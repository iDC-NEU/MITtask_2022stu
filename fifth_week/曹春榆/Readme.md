实现了shardkv的controller(4A)及shardkv的存储(4B)

其中shardkv的controller实现较为简单，使用复制状态机执行并返回相应的配置信息即可。

shardkv的存储主要难点在于配置变化时分片的迁移。

为了使集群中的分片服务器都处于同一个配置，集群中的机器每次都只请求其配置编号 + 1的配置，并不请求最新的配置。

然后在新配置到来时将其以命令的方式应用在Raft中，保证了大多数的机器同时更新配置。

当从Raft中得到新配置的信息的命令时，首先检查服务器上一个配置的更新是否完成（包括不再拥有的分片的发送，新分片的接收）。

新配置一旦被应用，服务器不再拥有的分片即停止了服务，服务器拥有的但还没有到来的分片也不会提供服务，保证了数据的一致性。然后，服务器会对这些分片进行标记，一个后台协程会对相应的数据进行发送和接收。

同时和lab3不同的是，实验中对每个分片都建立了客户端最后对于该分片的请求号（实验3是对于所有数据的请求号），这样防止当客户端持有的配置较新时（服务器是递增的配置请求，可能配置会交旧），在分片变化前写入了一个服务器中，但很快又被另一个shard的请求覆盖了，在分片迁移后又重新写入了这个请求，造成了二次写入，导致了数据的不一致。



系统测试的目录为`src/shardctrler`和`src/shardkv`

系统测试的命令为：

```shell
go test #不需要-race
```

不需要-race是因为在实验2的raft实现中，程序对于其中一个部分的数据并不敏感，且加上了数据变化后的约束，所以不需要加锁来读，但-race在这里会频繁warning。